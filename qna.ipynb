{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# All the libraries needed \r\n",
    "import pandas as pd \r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "________________________________________________________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q1 How to perform one hot encoding for multi categorical variables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "  df = pd.read_csv(\"Data/benz/train.csv\",usecols=[\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  X1  X2 X3 X4 X5 X6\n",
       "0  v  at  a  d  u  j\n",
       "1  t  av  e  d  y  l\n",
       "2  w   n  c  d  x  j\n",
       "3  t   n  f  d  x  l\n",
       "4  v   n  f  d  h  d"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "# How many categories are in each column\r\n",
    "for col in df.columns:\r\n",
    "    print(col,\": \",len(df[col].unique()),\" labels\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X1 :  27  labels\n",
      "X2 :  44  labels\n",
      "X3 :  7  labels\n",
      "X4 :  4  labels\n",
      "X5 :  29  labels\n",
      "X6 :  12  labels\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# Lets see how many columns we get after OHC\r\n",
    "pd.get_dummies(df,drop_first=True).shape\r\n",
    "\r\n",
    "# There are now total 117 variables\r\n",
    "# What can we do instead?"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4209, 117)"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "# We can take the most frequent categories from the data to get the \r\n",
    "# lets take only 20 categories\r\n",
    "df.X1.value_counts().sort_values(ascending=False).head(20)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "aa    833\n",
       "s     598\n",
       "b     592\n",
       "l     590\n",
       "v     408\n",
       "r     251\n",
       "i     203\n",
       "a     143\n",
       "c     121\n",
       "o      82\n",
       "w      52\n",
       "z      46\n",
       "u      37\n",
       "e      33\n",
       "m      32\n",
       "t      31\n",
       "h      29\n",
       "f      23\n",
       "y      23\n",
       "j      22\n",
       "Name: X1, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# lets get the to 10 categories in X2\r\n",
    "top_10 = df.X2.value_counts().sort_values(ascending=False).index[:10].to_list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "#for label in top_10:\r\n",
    "#    df[label] = np.where(df[\"X2\"]==label,1,0)\r\n",
    "#df[[\"X2\"]+top_10].head(20)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "# Now we can make function to do this task for all the categorical variables\r\n",
    "def top_n_categories(df,variable,top_n):\r\n",
    "    top_n_categories = df[variable].value_counts().sort_values(ascending=False).index[:top_n].to_list()\r\n",
    "    for label in top_n_categories:\r\n",
    "        df[variable+\"_\"+label] = np.where(df[variable]==label,1,0)\r\n",
    "    return df\r\n",
    "\r\n",
    "# Checking all the categorical columns in ou dataframe\r\n",
    "categorical_cols = [column for column in df.columns if df[column].dtype == \"O\"]\r\n",
    "\r\n",
    "# Creating all the One hot encoded variables\r\n",
    "for col in categorical_cols:\r\n",
    "    top_n_categories(df,col,5)\r\n",
    "\r\n",
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4209, 35)"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Advantages \r\n",
    "1. Requires less amount of time\r\n",
    "2. saves feature space\r\n",
    "## Disadvantage\r\n",
    "1. Does'nt add any new info to variable that can improve accuracy\r\n",
    "2. And we are loosing some amount of information here \r\n",
    "3. **Importantly** This code is prone to error when there are not enough categories in the variable and you are asking for n categories"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Other Approaches\r\n",
    "* **Target Encoding** ---> Where the categories are encoded as the mean of the target variable respectively fro each category\r\n",
    "    * One problem is that it decodes categorical variable based on the target only and can cause problems with other\r\n",
    "    * Rare categories---> in this case mean can or can not represent the category clearly\r\n",
    "        * We can use smooting using m smoothin larger values of m will be useful in case of rare categories    \r\n",
    "                        from category_encoders import MEstimateEncodercan be used\r\n",
    "* **Bayesian Target Encoding** is a more mathematically involved approach towards using the target as an encoding method. Using only the mean can be a deceiving metric, so Bayesian target encoding seeks to incorporate other statistical measures of the target variable’s distribution, such as its variance or its skewness — referred to as ‘higher moments’.\r\n",
    " "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Probability ratio (Odds) Encodicng"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* We do it in the case of y variable being the binary categorical variable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "  df = pd.read_csv(\"Data/benz/train.csv\",usecols=[\"X1\",\"X2\",\"X3\",\"X4\",\"X5\",\"X6\",\"y\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.81</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.53</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.26</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.62</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78.02</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y X1  X2 X3 X4 X5 X6\n",
       "0  130.81  v  at  a  d  u  j\n",
       "1   88.53  t  av  e  d  y  l\n",
       "2   76.26  w   n  c  d  x  j\n",
       "3   80.62  t   n  f  d  x  l\n",
       "4   78.02  v   n  f  d  h  d"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "________________________________________"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q2 Why do we need to perform feature scaling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* Each numerical variable data have units and magnitude. The unit part determines the numeric value for the data and when we are talking about many variables we see that the units of them can not be same (for weight and height) so we can actually compare the two variables.\r\n",
    "But some machine learning alsorithms especially eucledian distance based algo like (KNN and KMeans) tends to compare the vectors of these variables using the distance between the two vectors and there it can make problem to not have the same unit.\r\n",
    "* So to ignore such errors in the modelling we scale our feature.\r\n",
    "For some algorithms its necessary to scale while in others it is beneficial to scale for the effectiveness of the algorith eg. in Linear Regression if we scale our variables in such a way that it doesn have to do that many iteration or the ranomely selected weights vector is already near to the global minimum in gradient descent\r\n",
    "* In Some algos like Decision tree, Random Forest and XGboost we don't reqire it"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "84f017cd5557d2282cf5678dc1cdd116ebcd7e7555acfe7e9218cdeda5a0331f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}